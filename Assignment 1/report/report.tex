\documentclass[11pt]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage[margin=.8in,top=1.1in,bottom=1.1in]{geometry} % page layout
\usepackage{amsmath,amsthm,amssymb,amsfonts} % math things
\usepackage{graphicx} % include graphics
\usepackage{fancyhdr} % header customization
\usepackage{titlesec} % help with section naming
\usepackage{csquotes}
\usepackage{color}

% headers
\pagestyle{fancy} 
\fancyhf{} % clear all
\fancyhead[L]{\sffamily\small Lab Course: High Performance Computing --- Assignment Report}
\fancyhead[R]{\sffamily\small Page \thepage}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.2pt}
\markright{\hrulefill\quad}

\newcommand{\hwhead}[4]{
\begin{center}
\sffamily\large\bfseries Lab Course: High Performance Computing Assignment Report #1
\vspace{2mm} 
\normalfont

#2

#3
\end{center}
\vspace{6mm} \hrule \vspace{4mm}
}

% ------------------------------------------------------------------------------
% Start here -- Fill in your name, imat and email
% ------------------------------------------------------------------------------

\newcommand{\namea}{Frédéric Gillioz (03657002) \texttt{frederic.gillioz@tum.de}}
\newcommand{\nameb}{Andreas Amler (????) \texttt{???}}

\begin{document}

% ------------------------------------------------------------------------------
% Change xx (and only xx) to the current sheet number
% ------------------------------------------------------------------------------
\hwhead{1}{\namea}{\nameb}

% ------------------------------------------------------------------------------
% Fill in your solutions
% ------------------------------------------------------------------------------

\setcounter{section}{-1}
\section{General}

\begin{itemize}
\item Intel compiler 2017 installation on Ubuntu: Extracted installer package may not be located in a path containing a space character otherwise the installation procedure fails at the licensing step.
\item We have set-up a GitHub repository for collaborative working on the deliverables.
\end{itemize}

\section{Auto-vectorization}

\subsubsection*{Which kinds of loops can be vectorized automatically?}
Following conditions must be fulfilled:
\begin{itemize}
\item Innermost loops: With the exception of outer loops that were transformed into inner loops due to some previous loop optimizations.
\item No prohibiting data dependencies.
\item Unit stride: Loop increment by one only.
\item Supported operations and data types in the loop body.
\item Countable: The number of iterations must be known and fixed when entering the loop at runtime. The loop must only exit after the last iteration finished, in particular there may not be a data dependent exit point (\enquote{single entry and a single exit}).
\item Contain straight-line code: The control flow of every iteration must be the same in order to pack them into SIMD instructions. This implies no use of \texttt{switch}, \texttt{goto} or \texttt{return} statements within the loop body. There is one exception to this rule: Simple \texttt{if} statements are allowed, if they can be implemented as masked assignments, i.e. an instruction is applied to the whole SIMD register but the resulting scalars are written back selectively.
\item No function calls: Except intrinsic math functions and compatible functions, i.e. inline functions or functions qualified with \texttt{\_\_attribute\_\_(vector)} (Linux) that obey the other requirements listed here.
\end{itemize}

\subsubsection*{Which datatypes and operations are allowed in order to enable auto-vectorization of loops?}
\begin{itemize}
\item Integers: Most arithmetic and logical operators on 8-, 16- and 32-bit signed and unsigned integer data types are supported: \texttt{+}, \texttt{-}, \texttt{*}, division (however only via run-time library call), \texttt{\&}, \texttt{|}, \texttt{\^}, \texttt{<<}, \texttt{>>}. Many mathematical functions such as \texttt{sqrt}, \texttt{min}, \texttt{max} and \texttt{abs} are also supported. There is limited support for 64-bit integer data types.
\item Decimals: For 32- and 64-bit floating-point numbers, SSE provides SIMD instructions for \texttt{+}, \texttt{-}, \texttt{*}, \texttt{/}, \texttt{min}, \texttt{max} and \texttt{sqrt}. Intrinsic math functions provided through a specialized vector mathematical run-time library add some more allowed operations such as trigonometric functions.
\end{itemize}

\subsubsection*{Which types of dependency analysis do the compiler perform?}
\begin{enumerate}
\item Proven dependencies\\Loop-carried dependencies:
\begin{itemize}
\item Read-after-write: A memory location written at iteration \texttt{i} is read at a later iteration \texttt{i+x}. Cannot safely be vectorized.
\item Write-after-read: A memory location read at iteration \texttt{i} is written at a later iteration \texttt{i+x}. Can safely be vectorized if there is no other use of that memory location in the loop body.
\item Write-after-write: The same memory location is written in different iterations. This can generally not be safely vectorized.
\end{itemize}
There is an exception for some reduction idioms (e.g. multiply-accumulate) that are recognized by the compiler and contain the above dependencies. These can still be safely vectorized.
\item Potential dependencies\\Pointer aliasing:
The compiler may check at compile or runtime (by inserting some checker code) for overlapping memory regions caused by pointer aliasing.
\end{enumerate}

\subsubsection*{How does programming style influence auto-vectorization?}
Programming style can inhibit vectorization. For example the existence of global pointers prevents the compiler to prove that there is no aliasing to a memory location which is subject to auto-vectorization. For the same reason one should make use of array notations instead of pointers whenever possible.

Manual loop optimizations, indirect addressing, misaligned data and array of structures (AoS) should be avoided.

\subsubsection*{Is there a way to assist the compiler through language extensions? If yes, please give details.}
In some cases, certain keywords or directives may be applied in the code in order to assist the auto-vectorization's dependency analysis. In the following distinguish proven and potential data dependencies. For proven data dependencies it is known at compile time for sure that there is a dependency which prohibits vectorization. A potential data dependency can only be detected at runtime, e.g. overlapping memory regions. Apart from the following macros and keywords, in order to deal with potential data dependencies the compiler might generate code to detect them at runtime and execute either the safe serial loop or a vectorized version.
\begin{itemize}
\item Pragmas just before the respective loop:
\begin{itemize}
\item \texttt{\#pragma novector}: Disables vectorization. Saves the code overhead for the runtime dependency check and vectorized loop version. Makes sense if there is no expected benefit from vectorization (e.g. small number of loop iterations) or it is known for sure that input and output memory regions will overlap.
\item \texttt{\#pragma ivdep}: Conversely, this ignores any potential data dependencies. Proven dependencies are not ignored. Saves the code overhead for the runtime dependency check and non-vectorized loop version. Potentially unsafe. Equivalent to the \texttt{restrict} keyword below.
\item \texttt{\#pragma loop count (n)}: Tells the compiler the typical number of loop iterations. Helps it to decide if vectorization would be beneficial.
\item \texttt{\#pragma vector always}: Vectorize even if the compiler thinks it is not beneficial. Does not ignore proven or potential data dependencies.
\item \texttt{\#pragma vector align}: Only for SSE instructions: Tells the compiler that the data in the loop is 16-bytes memory aligned. This allows for more efficient aligned data movement instructions to be used. Wrong usage results in SSE runtime exceptions.
\item \texttt{\#pragma vector nontemporal}: Tells the compiler that it should not consider temporal locality for the data. Allows to use more efficient store operations, bypassing the cache. Such a situation occurs for example when adding two vectors.
\end{itemize}
\item Keywords:
\begin{itemize}
\item \texttt{restrict}: Tells the compiler that it is safe to assume that the annotated pointer (or array) is not aliased, i.e. this pointer is the only reference to the pointed memory and memory does not overlap. Potentially unsafe. Equivalent to the \texttt{ivdep} pragma above.
\end{itemize}
\end{itemize}

Besides this, there exist compiler command line options that allow the compiler to globally collect information to improve its dependency analysis and trip count estimations (through interprocedural optimization).

The pragma \texttt{SIMD} is not listed here because it is not an auto-vectorization hint but a user-mandated vectorization that supplements auto-vectorization.

\subsubsection*{Which loop optimizations are performed by the compiler in order to vectorize and pipeline loops?}
\begin{itemize}
\item Loop sectioning (Strip-mining): Fragmenting a large loop into smaller segments plus a finalizing cleanup loop. One segment is subsequently processed by a single SIMD instruction. Might also increase the temporal and spatial locality in the data cache.
\item Loop blocking: Generalizes the idea of loop sectioning for higher dimensions. The primary goal of loop blocking is to optimize the cache usage.
\item Loop interchanging: Especially for the important use case of matrix-matrix multiplications, the three nested loops can be ordered in a way such that for all inner iterations the memory access happens with unit stride so that more efficient vectorization is possible.
\item Loop peeling: Data movement is more efficient if data is aligned to a 16-byte boundary (for SSE instructions). If the compiler cannot statically assure that this is the case, then it might generate code that peels off some iterations and performs them non-vectorized.
\item Loop collapsing: Some nested loops can be collapsed into a single loop.
\end{itemize}

There are some more loop optimization techniques such as loop unrolling that are not listed here because these aim generally at a higher performance independently of vectorization. However they can occur along vectorization.

\end{document}
